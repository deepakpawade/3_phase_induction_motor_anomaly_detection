{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online learning is a machine learning technique that allows a model to be updated with new data as it becomes available without the need to retrain the model from scratch.\n",
    "\n",
    "To implement online learning for an anomaly detection model, the model needs to be designed to handle incremental updates. One way to achieve this is by using techniques such as stochastic gradient descent, which allows the model to be updated incrementally based on the new data.\n",
    "\n",
    "The process for online learning in anomaly detection typically involves the following steps:\n",
    "\n",
    "Collect new data: As new data becomes available, it can be collected and added to the existing data set.\n",
    "\n",
    "Update the model: The model can be updated using the new data while preserving the knowledge gained from previous training.\n",
    "\n",
    "Test the model: The updated model should be tested using new data to ensure that it is still able to accurately detect anomalies.\n",
    "\n",
    "Repeat: The process can be repeated as new data becomes available, allowing the model to continuously learn and adapt to changing conditions.\n",
    "\n",
    "Overall, online learning provides a way to continuously improve the performance of an anomaly detection model over time, as new data becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../induction_motor_anomaly_detection/')\n",
    "import modules,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector:\n",
    "    def __init__(self, n_components=1, covariance_type='full', k_threshold_std_dev=3):\n",
    "        self.n_components = n_components\n",
    "        self.covariance_type = covariance_type\n",
    "        self.k_threshold_std_dev = k_threshold_std_dev\n",
    "        self.gmm = None\n",
    "        self.X = np.array([])\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Mixture Model to the training data.\n",
    "        \"\"\"\n",
    "        if self.gmm is None:\n",
    "            self.gmm = GaussianMixture(n_components=self.n_components, covariance_type=self.covariance_type)\n",
    "            self.gmm.fit(X)\n",
    "            self.X = X\n",
    "        else:\n",
    "            self.X = np.concatenate((self.X, X), axis=0)\n",
    "            self.gmm.fit(self.X)\n",
    "            \n",
    "        # This tells the GMM to initialize the model parameters using the k-means algorithm, which can be more efficient than the default random initialization for large datasets\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict whether the data is anomalous or not based on the GMM.\n",
    "        \"\"\"\n",
    "        scores = self.gmm.score_samples(self.X)\n",
    "        k = self.k_threshold_std_dev\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        threshold = mean_score - k * std_score\n",
    "        is_anomaly = self.gmm.score_samples(X_test) < threshold\n",
    "        return is_anomaly\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the modified code, the AnomalyDetector class has been updated to support online learning. The fit method now allows the model to be updated with new data, while the predict method returns the anomaly predictions based on the updated model.\n",
    "\n",
    "To use the updated AnomalyDetector class, you would first create an instance of the class and fit it to your initial training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = pd.read_csv('../data/combined_data.csv')\n",
    "anomalous_data = pd.read_csv('../anomalous_data/anomalous_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = modules.ElectricalFeatureExtractor(current_data=normal_data)\n",
    "test_data_features = modules.ElectricalFeatureExtractor(current_data=anomalous_data)\n",
    "train_scaler = scaler.Scaler()\n",
    "train_scaler.fit_unlabelled_data(train_data_features.feature_dataframe[0])\n",
    "train_scaled = train_scaler.transform(train_data_features.feature_dataframe[0])\n",
    "test_scaled = train_scaler.transform(test_data_features.feature_dataframe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomalous\n"
     ]
    }
   ],
   "source": [
    "modules.AnomalyDetector.GaussianMixture(train_feature_dataframe=train_scaled, test_feature_dataframe=test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector = AnomalyDetector(n_components=1, covariance_type='full', k_threshold_std_dev=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomalous\n",
      "[ True False]\n",
      "anomalous\n",
      "[ True False]\n",
      "anomalous\n",
      "[ True False]\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_scaled)\n",
    "try:\n",
    "    while True:\n",
    "        data = [next(it), next(it)]\n",
    "        anomaly_detector.fit(data) #GM need at least 2 datapoint\n",
    "        anomaly_predictions = anomaly_detector.predict(data)\n",
    "        if any(anomaly_predictions):\n",
    "            print('anomalous')\n",
    "            print(anomaly_predictions)\n",
    "        else:\n",
    "            # print('not anomalous')\n",
    "            pass\n",
    "            \n",
    "\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the predict method to get anomaly predictions for your test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomalous\n"
     ]
    }
   ],
   "source": [
    "anomaly_predictions = anomaly_detector.predict(test_scaled)\n",
    "if anomaly_predictions:\n",
    "    print('anomalous')\n",
    "else:\n",
    "    print('not anomalous')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "class OnlineIsolationForest:\n",
    "    def __init__(self, n_estimators=100, max_samples=256, contamination='auto', random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.contamination = contamination\n",
    "        self.random_state = random_state\n",
    "        self.iforest = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.iforest is None:\n",
    "            self.iforest = IsolationForest(n_estimators=self.n_estimators,\n",
    "                                           max_samples=self.max_samples,\n",
    "                                           contamination=self.contamination,\n",
    "                                           random_state=self.random_state)\n",
    "            self.iforest.fit(X)\n",
    "        else:\n",
    "            self.iforest.set_params(n_estimators=self.n_estimators,\n",
    "                                    max_samples=self.max_samples,\n",
    "                                    contamination=self.contamination,\n",
    "                                    random_state=self.random_state)\n",
    "            self.iforest.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.iforest is not None:\n",
    "            return self.iforest.predict(X)\n",
    "        else:\n",
    "            raise ValueError(\"Isolation Forest not yet fit\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
