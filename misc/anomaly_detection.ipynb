{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " 'anomaly_detection.ipynb',\n",
       " 'concepts.txt',\n",
       " 'data',\n",
       " 'PyEMD',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datafolder = os.listdir('data/s3Files/')\n",
    "# df = pd.concat([pd.read_csv(f, header=None,sep=',') for f in datafolder])\n",
    "df = pd.read_csv('data/s3Files/data2.txt',header=None,sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2102</td>\n",
       "      <td>2318</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2095</td>\n",
       "      <td>2326</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2   3   4\n",
       "0 NaN  2102  2318  97 NaN\n",
       "1 NaN  2095  2326  94 NaN"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[0,4],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['current_1', 'current_2', 'current_3']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform motor current signature analysis: You can use the scipy library to perform Fourier transforms on the current readings from each phase of the motor and plot the resulting frequency spectra. This will help you identify any anomalies or patterns in the spectra that may indicate a fault in the motor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2102</td>\n",
       "      <td>2318</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2095</td>\n",
       "      <td>2326</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2087</td>\n",
       "      <td>2336</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1867</td>\n",
       "      <td>2429</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1862</td>\n",
       "      <td>2430</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1809</td>\n",
       "      <td>2135</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1816</td>\n",
       "      <td>2136</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1824</td>\n",
       "      <td>2122</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1829</td>\n",
       "      <td>2121</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1835</td>\n",
       "      <td>2107</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1  current_2  current_3\n",
       "0          2102       2318         97\n",
       "1          2095       2326         94\n",
       "2          2087       2336         78\n",
       "3          1867       2429        283\n",
       "4          1862       2430        297\n",
       "...         ...        ...        ...\n",
       "9995       1809       2135        789\n",
       "9996       1816       2136        790\n",
       "9997       1824       2122        790\n",
       "9998       1829       2121        791\n",
       "9999       1835       2107        795\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[4] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2102</td>\n",
       "      <td>2318</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2095</td>\n",
       "      <td>2326</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2087</td>\n",
       "      <td>2336</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1867</td>\n",
       "      <td>2429</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1809</td>\n",
       "      <td>2135</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1816</td>\n",
       "      <td>2136</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1824</td>\n",
       "      <td>2122</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1829</td>\n",
       "      <td>2121</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1835</td>\n",
       "      <td>2107</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1  current_2  current_3\n",
       "0          2102       2318         97\n",
       "1          2095       2326         94\n",
       "2          2087       2336         78\n",
       "3          1867       2429        283\n",
       "4         10000      10000      10000\n",
       "...         ...        ...        ...\n",
       "9995       1809       2135        789\n",
       "9996       1816       2136        790\n",
       "9997       1824       2122        790\n",
       "9998       1829       2121        791\n",
       "9999       1835       2107        795\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54407143,  0.68071122, -1.23440259],\n",
       "       [ 0.50889197,  0.72149975, -1.24469526],\n",
       "       [ 0.46868688,  0.77248542, -1.29958948],\n",
       "       ...,\n",
       "       [-0.85305563, -0.31860792,  1.14320339],\n",
       "       [-0.82792745, -0.32370649,  1.14663428],\n",
       "       [-0.79777362, -0.39508643,  1.16035784]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "\n",
    "fft_data = fft(scaled_df, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00961995-0.j        ,  0.82091712-1.65853721j,\n",
       "        0.82091712+1.65853721j])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform model-based VI analysis: To perform model-based VI analysis, you will need to create a mathematical model of the motor that takes into account both its electrical and mechanical behavior. This can be done using tools like MATLAB/Simulink or Python libraries like pyEMD. Once you have created the model, you can use it to predict the expected behavior of the motor's electrical and mechanical signals and compare it to the actual behavior to detect any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyEMD import EMD #pip install EMD-signal\n",
    "\n",
    "emd = EMD()\n",
    "imfs = emd(df.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(fft_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create condition indicators and features: Based on the results of your MCSA and model-based VI analyses, you can create condition indicators and features that can be used to train an ML model. For example, you might extract frequency spectrum peaks, statistical properties of the data, or time-domain features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "peak_freqs = np.argmax(fft_data, axis=1)\n",
    "mean_currents = np.mean(df, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1505.666667\n",
       "1        1505.000000\n",
       "2        1500.333333\n",
       "3        1526.333333\n",
       "4       10000.000000\n",
       "            ...     \n",
       "9995     1577.666667\n",
       "9996     1580.666667\n",
       "9997     1578.666667\n",
       "9998     1580.333333\n",
       "9999     1579.000000\n",
       "Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_currents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to detect anomalies, but one common method is to use a statistical approach based on the distribution of the feature values. For example, you could calculate the mean and standard deviation of the feature values and define a threshold for detecting anomalies based on how many standard deviations away from the mean a value is. Any feature values that fall outside this threshold would be flagged as potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean and standard deviation of peak frequency data\n",
    "mean_freq = np.mean(mean_currents)\n",
    "std_freq = np.std(mean_currents)\n",
    "\n",
    "\n",
    "# Define threshold for detecting anomalies\n",
    "thresh_freq = mean_freq + 3 * std_freq\n",
    "\n",
    "# Identify potential anomalies\n",
    "anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(peak_freqs > thresh_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4517.    -0.j        ,  894.5-1923.44242181j,\n",
       "         894.5+1923.44242181j],\n",
       "       [4515.    -0.j        ,  885. -1932.96870125j,\n",
       "         885. +1932.96870125j],\n",
       "       [4501.    -0.j        ,  880. -1955.48536175j,\n",
       "         880. +1955.48536175j],\n",
       "       ...,\n",
       "       [4736.    -0.j        ,  368. -1153.54583784j,\n",
       "         368. +1153.54583784j],\n",
       "       [4741.    -0.j        ,  373. -1151.81378703j,\n",
       "         373. +1151.81378703j],\n",
       "       [4737.    -0.j        ,  384. -1136.22532977j,\n",
       "         384. +1136.22532977j]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "import numpy as np\n",
    "\n",
    "def get_anomalies(df):\n",
    "    \n",
    "    # Perform FFT on the data\n",
    "    fft_data = fft(df.to_numpy(), axis=1)\n",
    "\n",
    "    # Calculate the peak frequency for each IMFs\n",
    "    peak_freqs = np.argmax(fft_data, axis=1)\n",
    "\n",
    "    # Calculate the mean current for each row\n",
    "    mean_currents = np.mean(df, axis=1)\n",
    "\n",
    "    # Calculate the mean and standard deviation of peak frequency data\n",
    "    mean_freq = np.mean(mean_currents)\n",
    "    std_freq = np.std(mean_currents)\n",
    "\n",
    "    # Define threshold for detecting anomalies\n",
    "    thresh_freq = mean_freq + 3 * std_freq\n",
    "\n",
    "    # Identify potential anomalies\n",
    "    anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n",
    "    \n",
    "    return anomalies_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datafolder = os.listdir('data/s3Files/')\n",
    "# df = pd.concat([pd.read_csv(f, header=None,sep=',') for f in datafolder])\n",
    "\n",
    "for file in datafolder:\n",
    "   df = pd.concat([pd.read_csv('data/s3Files/'+file,header=None,sep=',')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[0,4],inplace=True)\n",
    "df.columns = ['current_1', 'current_2', 'current_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_anomalies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df1 = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# select a random row index to introduce anomalies\n",
    "row_idx = random.randint(0, len(df1)-1)\n",
    "\n",
    "# add random noise to the selected row\n",
    "df1.iloc[row_idx] += np.random.normal(0, 0.1, len(df1.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_anomalies(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959</td>\n",
       "      <td>2389</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1952</td>\n",
       "      <td>2391</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1942</td>\n",
       "      <td>2390</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1941</td>\n",
       "      <td>2393</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1930</td>\n",
       "      <td>2395</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2214</td>\n",
       "      <td>1978</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2217</td>\n",
       "      <td>1985</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2218</td>\n",
       "      <td>1989</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2220</td>\n",
       "      <td>1996</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2221</td>\n",
       "      <td>2002</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1  current_2  current_3\n",
       "0          1959       2389        106\n",
       "1          1952       2391        118\n",
       "2          1942       2390        124\n",
       "3          1941       2393        126\n",
       "4          1930       2395        126\n",
       "...         ...        ...        ...\n",
       "9995       2214       1978        368\n",
       "9996       2217       1985        358\n",
       "9997       2218       1989        346\n",
       "9998       2220       1996        337\n",
       "9999       2221       2002        323\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code seems correct. It first generates random indices to modify a specified number of values in the chunk. Then, it modifies the values at those indices by adding a random deviation. After that, it processes the modified chunk data using FFT to obtain the peak frequencies and compute the threshold. Finally, it checks for anomalies and alerts if any are detected.\n",
    "\n",
    "However, it is important to note that the specific parameters used, such as the number of anomalies and the maximum deviation, may need to be adjusted depending on the characteristics of the data being analyzed. Additionally, it would be a good practice to split the data into training and testing sets, and only introduce anomalies in the testing set to evaluate the performance of the anomaly detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define the chunk size and anomaly threshold\n",
    "chunk_size = 10000  # process 10000 rows at a time\n",
    "# anomaly_thresh = 0.5  # set the anomaly threshold\n",
    "\n",
    "# Read the data in chunks\n",
    "datafolder = 'data/s3Files/'\n",
    "data_files = os.listdir(datafolder)\n",
    "\n",
    "# Iterate over the files and process the data in chunks\n",
    "for file in data_files:\n",
    "    # Load the data chunk by chunk\n",
    "    for chunk in pd.read_csv(datafolder + file, header=None, chunksize=chunk_size):\n",
    "\n",
    "\n",
    "        # Generate random indices to modify\n",
    "        num_anomalies = 100\n",
    "        anomaly_indices = np.random.choice(chunk.index, num_anomalies, replace=False)\n",
    "\n",
    "        # Modify the values at the anomaly indices\n",
    "        max_deviation = 24\n",
    "        for index in anomaly_indices:\n",
    "            row = chunk.loc[index]\n",
    "            col = np.random.choice(chunk.columns)\n",
    "            deviation = max_deviation * np.random.random()\n",
    "            chunk.loc[index, col] = row[col] + deviation\n",
    "       \n",
    "        scaler = StandardScaler()\n",
    "        scaled_df = scaler.fit_transform(df)\n",
    "\n",
    "        # Process the chunk data\n",
    "        fft_data = fft(chunk.to_numpy(), axis=1)\n",
    "        peak_freqs = np.argmax(fft_data, axis=1)\n",
    "        mean_currents = np.mean(chunk, axis=1)\n",
    "        mean_freq = np.mean(peak_freqs)\n",
    "        std_freq = np.std(peak_freqs)\n",
    "        thresh_freq = mean_freq + 3 * std_freq\n",
    "        anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n",
    "        # print(thresh_freq)\n",
    "        \n",
    "        # Check for anomalies and alert if detected\n",
    "        if len(anomalies_freq) > 0:\n",
    "            print(f\"Anomaly detected in {file}: {len(anomalies_freq)} anomalies detected in chunk {chunk.index[0]} - {chunk.index[-1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0398511a9cde84ab83a2fa188ff6508a33d7c0397b3581839dbbf3238a247df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
