{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define the chunk size and anomaly threshold\n",
    "chunk_size = 10000  # process 10000 rows at a time\n",
    "# anomaly_thresh = 0.5  # set the anomaly threshold\n",
    "\n",
    "# Read the data in chunks\n",
    "datafolder = 'data/s3Files/'\n",
    "data_files = os.listdir(datafolder)\n",
    "\n",
    "# Iterate over the files and process the data in chunks\n",
    "for file in data_files:\n",
    "    # Load the data chunk by chunk\n",
    "    for chunk in pd.read_csv(datafolder + file, header=None, chunksize=chunk_size):\n",
    "\n",
    "\n",
    "        # Generate random indices to modify\n",
    "        num_anomalies = 100\n",
    "        anomaly_indices = np.random.choice(chunk.index, num_anomalies, replace=False)\n",
    "\n",
    "        # Modify the values at the anomaly indices\n",
    "        max_deviation = 24\n",
    "        for index in anomaly_indices:\n",
    "            row = chunk.loc[index]\n",
    "            col = np.random.choice(chunk.columns)\n",
    "            deviation = max_deviation * np.random.random()\n",
    "            chunk.loc[index, col] = row[col] + deviation\n",
    "       \n",
    "        scaler = StandardScaler()\n",
    "        chunk = scaler.fit_transform(chunk)\n",
    "\n",
    "        # Process the chunk data\n",
    "        fft_data = fft(chunk, axis=1)\n",
    "        peak_freqs = np.argmax(fft_data, axis=1)\n",
    "        mean_currents = np.mean(chunk, axis=1)\n",
    "        mean_freq = np.mean(peak_freqs)\n",
    "        std_freq = np.std(peak_freqs)\n",
    "        thresh_freq = mean_freq + 3 * std_freq\n",
    "        anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n",
    "        # print(thresh_freq)\n",
    "        \n",
    "        # Check for anomalies and alert if detected\n",
    "        if len(anomalies_freq) > 0:\n",
    "            print(f\"Anomaly detected in {file}: {len(anomalies_freq)} anomalies detected in chunk {chunk.index[0]} - {chunk.index[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/s3Files/data10.txt',header=None,sep=',')\n",
    "df.drop(columns=[0,4],inplace=True)\n",
    "df.columns = ['current_1', 'current_2', 'current_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anomalies = 10\n",
    "anomaly_indices = np.random.choice(df.index, num_anomalies, replace=False)\n",
    "for index in anomaly_indices:\n",
    "    row = df.loc[index]\n",
    "    col = np.random.choice(df.columns)\n",
    "    df.loc[index, col] = row[col] + 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ano(chunk):\n",
    "    scaler = StandardScaler()\n",
    "    chunk = scaler.fit_transform(chunk)\n",
    "\n",
    "    # Process the chunk data\n",
    "    fft_data = fft(chunk, axis=1)\n",
    "    peak_freqs = np.argmax(fft_data, axis=1)\n",
    "    mean_currents = np.mean(chunk, axis=1)\n",
    "    mean_freq = np.mean(peak_freqs)\n",
    "    std_freq = np.std(peak_freqs)\n",
    "    thresh_freq = mean_freq + 3 * std_freq\n",
    "    anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n",
    "    # print(thresh_freq)\n",
    "    \n",
    "    # Check for anomalies and alert if detected\n",
    "    if len(anomalies_freq) > 0:\n",
    "        print(f\"Anomaly detected{len(anomalies_freq)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ano(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/s3Files/data12.txt',header=None,sep=',')\n",
    "df.drop(columns=[0,4],inplace=True)\n",
    "df.columns = ['current_1', 'current_2', 'current_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "current_1    2255\n",
       "current_2    2453\n",
       "current_3     846\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anomalies = 10\n",
    "anomaly_indices = np.random.choice(df.index, num_anomalies, replace=False)\n",
    "for index in anomaly_indices:\n",
    "    row = df.loc[index]\n",
    "    col = np.random.choice(df.columns)\n",
    "    df.loc[index, col] = row[col] + 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>2398</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955</td>\n",
       "      <td>2398</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948</td>\n",
       "      <td>2399</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1942</td>\n",
       "      <td>2398</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1938</td>\n",
       "      <td>2398</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2218</td>\n",
       "      <td>1902</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2215</td>\n",
       "      <td>1925</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2233</td>\n",
       "      <td>1927</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2220</td>\n",
       "      <td>1933</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2217</td>\n",
       "      <td>1935</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1  current_2  current_3\n",
       "0          1961       2398        122\n",
       "1          1955       2398        131\n",
       "2          1948       2399        140\n",
       "3          1942       2398        150\n",
       "4          1938       2398        156\n",
       "...         ...        ...        ...\n",
       "9995       2218       1902        493\n",
       "9996       2215       1925        464\n",
       "9997       2233       1927        481\n",
       "9998       2220       1933        476\n",
       "9999       2217       1935        470\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# chunk = scaler.fit_transform(df)\n",
    "chunk = (df - df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_data = fft(chunk.to_numpy(), axis=1)\n",
    "peak_freqs = np.argmax(fft_data, axis=1)\n",
    "mean_currents = np.mean(chunk, axis=1)\n",
    "mean_freq = np.mean(peak_freqs)\n",
    "std_freq = np.std(peak_freqs)\n",
    "thresh_freq = mean_freq + 3 * std_freq / np.mean(chunk.std(axis=1))\n",
    "anomalies_freq = np.where(peak_freqs > thresh_freq)[0]\n",
    "anomalies_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[10:100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_freqs[10:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "peak freqs will always be within 0,1,2 and thresh will always be something > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(peak_freqs > thresh_freq)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0398511a9cde84ab83a2fa188ff6508a33d7c0397b3581839dbbf3238a247df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
